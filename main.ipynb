{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install openai-whisper\n",
        "!pip install scenedetect[opencv]\n",
        "!pip install torch\n",
        "!pip install google-generativeai\n",
        "!pip install python-dotenv\n",
        "\n",
        "# Verify FFmpeg is installed\n",
        "!ffmpeg -version\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"1. Get FREE Gemini API key from: https://makersuite.google.com/app/apikey\")\n",
        "print(\"2. Set GEMINI_API_KEY in next cell\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WqPcfakFZjB",
        "outputId": "795e3c7a-0264-41f9-8971-fcccc259391d"
      },
      "id": "_WqPcfakFZjB",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Collecting triton>=2 (from openai-whisper)\n",
            "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=de9b9498f7413636612d939da09770bb47235550b8c62c88fe848f3f458a9fdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, openai-whisper\n",
            "Successfully installed openai-whisper-20250625 triton-3.5.1\n",
            "Collecting scenedetect[opencv]\n",
            "  Downloading scenedetect-0.6.7.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting click<8.3.0,~=8.0 (from scenedetect[opencv])\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scenedetect[opencv]) (2.0.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from scenedetect[opencv]) (4.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scenedetect[opencv]) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from scenedetect[opencv]) (4.12.0.88)\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scenedetect-0.6.7.1-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: click, scenedetect\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.1\n",
            "    Uninstalling click-8.3.1:\n",
            "      Successfully uninstalled click-8.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "rasterio 1.5.0 requires click!=8.2.*,>=4.0, but you have click 8.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.2.1 scenedetect-0.6.7.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2026.1.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n",
            "‚úÖ Installation complete!\n",
            "\n",
            "Next steps:\n",
            "1. Get FREE Gemini API key from: https://makersuite.google.com/app/apikey\n",
            "2. Set GEMINI_API_KEY in next cell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Replace with your actual API key from https://makersuite.google.com/app/apikey\n",
        "GEMINI_API_KEY = \"AIzaSyBs69fqlkG61HHy1iGoV6PwBPOJ486xMtY\" # Assuming you updated this line\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "\n",
        "print(f\"‚úÖ API Key set: {GEMINI_API_KEY[:10]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8MNcUuLFxdm",
        "outputId": "fa1d52fc-449b-479e-b13e-99c7126398a0"
      },
      "id": "E8MNcUuLFxdm",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key set: AIzaSyBs69...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Create directories\n",
        "Path(\"extraction_output\").mkdir(exist_ok=True)\n",
        "Path(\"editing_output\").mkdir(exist_ok=True)\n",
        "Path(\"final_videos\").mkdir(exist_ok=True)\n",
        "Path(\"enhanced_videos\").mkdir(exist_ok=True)\n",
        "Path(\"cut_markers\").mkdir(exist_ok=True)\n",
        "Path(\"previews\").mkdir(exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Project directories created:\")\n",
        "print(\"  - extraction_output/  (Day 1 outputs)\")\n",
        "print(\"  - editing_output/     (Day 2 outputs)\")\n",
        "print(\"  - final_videos/       (Day 3 outputs)\")\n",
        "print(\"  - enhanced_videos/    (Day 4 outputs)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqxy333cF6rA",
        "outputId": "61aea6ef-b647-42d2-eb56-1cadddaa6aad"
      },
      "id": "Jqxy333cF6rA",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Project directories created:\n",
            "  - extraction_output/  (Day 1 outputs)\n",
            "  - editing_output/     (Day 2 outputs)\n",
            "  - final_videos/       (Day 3 outputs)\n",
            "  - enhanced_videos/    (Day 4 outputs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import json\n",
        "from scenedetect import detect, ContentDetector\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class VideoSensorSuite:\n",
        "    def __init__(self, video_path):\n",
        "        self.video_path = Path(video_path)\n",
        "        self.output_dir = Path(\"extraction_output\")\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def extract_audio_transcription(self, model_size=\"base\"):\n",
        "        \"\"\"Extract audio transcription with timestamps using Whisper\"\"\"\n",
        "        print(f\"üé§ Loading Whisper model ({model_size})...\")\n",
        "        model = whisper.load_model(model_size)\n",
        "\n",
        "        print(f\"üé§ Transcribing audio from {self.video_path.name}...\")\n",
        "        result = model.transcribe(\n",
        "            str(self.video_path),\n",
        "            verbose=False,\n",
        "            word_timestamps=True\n",
        "        )\n",
        "\n",
        "        transcription_data = {\n",
        "            \"text_full\": result[\"text\"],\n",
        "            \"language\": result[\"language\"],\n",
        "            \"segments\": []\n",
        "        }\n",
        "\n",
        "        for seg in result[\"segments\"]:\n",
        "            segment_data = {\n",
        "                \"id\": seg[\"id\"],\n",
        "                \"start\": seg[\"start\"],\n",
        "                \"end\": seg[\"end\"],\n",
        "                \"text\": seg[\"text\"].strip(),\n",
        "                \"words\": []\n",
        "            }\n",
        "\n",
        "            if \"words\" in seg:\n",
        "                for word in seg[\"words\"]:\n",
        "                    segment_data[\"words\"].append({\n",
        "                        \"word\": word[\"word\"].strip(),\n",
        "                        \"start\": word[\"start\"],\n",
        "                        \"end\": word[\"end\"]\n",
        "                    })\n",
        "\n",
        "            transcription_data[\"segments\"].append(segment_data)\n",
        "\n",
        "        transcription_file = self.output_dir / f\"{self.video_path.stem}_transcription.json\"\n",
        "        with open(transcription_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(transcription_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"‚úÖ Transcription saved: {transcription_file}\")\n",
        "        print(f\"   - Language: {result['language']}\")\n",
        "        print(f\"   - Segments: {len(transcription_data['segments'])}\")\n",
        "\n",
        "        return transcription_data\n",
        "\n",
        "    def detect_scene_changes(self, threshold=27.0):\n",
        "        \"\"\"Detect scene changes using PySceneDetect\"\"\"\n",
        "        print(f\"üé¨ Detecting scene changes in {self.video_path.name}...\")\n",
        "\n",
        "        scene_list = detect(\n",
        "            str(self.video_path),\n",
        "            ContentDetector(threshold=threshold)\n",
        "        )\n",
        "\n",
        "        scenes_data = {\n",
        "            \"total_scenes\": len(scene_list),\n",
        "            \"scenes\": []\n",
        "        }\n",
        "\n",
        "        for i, scene in enumerate(scene_list):\n",
        "            start_time = scene[0].get_seconds()\n",
        "            end_time = scene[1].get_seconds()\n",
        "\n",
        "            scene_data = {\n",
        "                \"scene_id\": i + 1,\n",
        "                \"start\": start_time,\n",
        "                \"end\": end_time,\n",
        "                \"duration\": end_time - start_time,\n",
        "                \"start_frame\": scene[0].get_frames(),\n",
        "                \"end_frame\": scene[1].get_frames()\n",
        "            }\n",
        "\n",
        "            scenes_data[\"scenes\"].append(scene_data)\n",
        "\n",
        "        scenes_file = self.output_dir / f\"{self.video_path.stem}_scenes.json\"\n",
        "        with open(scenes_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(scenes_data, f, indent=2)\n",
        "\n",
        "        print(f\"‚úÖ Scene detection saved: {scenes_file}\")\n",
        "        print(f\"   - Total scenes: {len(scene_list)}\")\n",
        "\n",
        "        return scenes_data\n",
        "\n",
        "    def merge_to_master_log(self, transcription_data, scenes_data):\n",
        "        \"\"\"Merge transcription and scene data into master_log.json\"\"\"\n",
        "        print(f\"üîó Merging data into master log...\")\n",
        "\n",
        "        master_log = {\n",
        "            \"video_file\": self.video_path.name,\n",
        "            \"video_path\": str(self.video_path.absolute()),\n",
        "            \"metadata\": {\n",
        "                \"language\": transcription_data.get(\"language\", \"unknown\"),\n",
        "                \"total_scenes\": scenes_data[\"total_scenes\"],\n",
        "                \"total_segments\": len(transcription_data[\"segments\"]),\n",
        "                \"full_transcript\": transcription_data[\"text_full\"]\n",
        "            },\n",
        "            \"timeline\": []\n",
        "        }\n",
        "\n",
        "        for segment in transcription_data[\"segments\"]:\n",
        "            seg_start = segment[\"start\"]\n",
        "            seg_end = segment[\"end\"]\n",
        "\n",
        "            overlapping_scenes = []\n",
        "            for scene in scenes_data[\"scenes\"]:\n",
        "                if not (seg_end < scene[\"start\"] or seg_start > scene[\"end\"]):\n",
        "                    overlapping_scenes.append(scene[\"scene_id\"])\n",
        "\n",
        "            timeline_entry = {\n",
        "                \"type\": \"segment\",\n",
        "                \"id\": segment[\"id\"],\n",
        "                \"start\": seg_start,\n",
        "                \"end\": seg_end,\n",
        "                \"duration\": seg_end - seg_start,\n",
        "                \"text\": segment[\"text\"],\n",
        "                \"words\": segment[\"words\"],\n",
        "                \"scenes\": overlapping_scenes\n",
        "            }\n",
        "\n",
        "            master_log[\"timeline\"].append(timeline_entry)\n",
        "\n",
        "        for scene in scenes_data[\"scenes\"]:\n",
        "            has_dialogue = any(\n",
        "                scene[\"scene_id\"] in entry.get(\"scenes\", [])\n",
        "                for entry in master_log[\"timeline\"]\n",
        "            )\n",
        "\n",
        "            if not has_dialogue:\n",
        "                timeline_entry = {\n",
        "                    \"type\": \"visual_only\",\n",
        "                    \"scene_id\": scene[\"scene_id\"],\n",
        "                    \"start\": scene[\"start\"],\n",
        "                    \"end\": scene[\"end\"],\n",
        "                    \"duration\": scene[\"duration\"],\n",
        "                    \"text\": None,\n",
        "                    \"scenes\": [scene[\"scene_id\"]]\n",
        "                }\n",
        "                master_log[\"timeline\"].append(timeline_entry)\n",
        "\n",
        "        master_log[\"timeline\"].sort(key=lambda x: x[\"start\"])\n",
        "\n",
        "        master_log_file = self.output_dir / f\"{self.video_path.stem}_master_log.json\"\n",
        "        with open(master_log_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(master_log, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"‚úÖ Master log created: {master_log_file}\")\n",
        "        print(f\"   - Timeline entries: {len(master_log['timeline'])}\")\n",
        "\n",
        "        return master_log\n",
        "\n",
        "    def run_full_extraction(self, whisper_model=\"base\", scene_threshold=27.0):\n",
        "        \"\"\"Run the complete extraction pipeline\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üöÄ Starting Video Extraction Pipeline\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        try:\n",
        "            transcription_data = self.extract_audio_transcription(model_size=whisper_model)\n",
        "            scenes_data = self.detect_scene_changes(threshold=scene_threshold)\n",
        "            master_log = self.merge_to_master_log(transcription_data, scenes_data)\n",
        "\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"‚úÖ EXTRACTION COMPLETE\")\n",
        "            print(\"=\"*60)\n",
        "            print(f\"Output directory: {self.output_dir.absolute()}\")\n",
        "            print(f\"Master log: {self.video_path.stem}_master_log.json\")\n",
        "\n",
        "            return master_log\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error during extraction: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            raise\n",
        "\n",
        "# Save class for later use\n",
        "print(\"‚úÖ Day 1 extraction pipeline ready!\")\n",
        "print(\"\\nUsage:\")\n",
        "print(\"  sensor = VideoSensorSuite('your_video.mp4')\")\n",
        "print(\"  sensor.run_full_extraction()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk9uRFpLIU4A",
        "outputId": "705105d2-a009-42af-986e-57c4b200a8cc"
      },
      "id": "Tk9uRFpLIU4A",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Day 1 extraction pipeline ready!\n",
            "\n",
            "Usage:\n",
            "  sensor = VideoSensorSuite('your_video.mp4')\n",
            "  sensor.run_full_extraction()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and modify this to run:\n",
        "video_file = \"/content/sample1.mp4\"\n",
        "sensor = VideoSensorSuite(video_file)\n",
        "master_log = sensor.run_full_extraction(whisper_model=\"base\", scene_threshold=27.0)\n",
        "\n",
        "print(\"üìù Modify the video_file path and uncomment to run extraction\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyN1jIh1GNgv",
        "outputId": "334716b0-d4b8-4a28-abf4-5326c4a71415"
      },
      "id": "iyN1jIh1GNgv",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üöÄ Starting Video Extraction Pipeline\n",
            "============================================================\n",
            "\n",
            "üé§ Loading Whisper model (base)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139M/139M [00:00<00:00, 195MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé§ Transcribing audio from sample1.mp4...\n",
            "Detected language: English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2995/2995 [00:28<00:00, 105.77frames/s]\n",
            "INFO:pyscenedetect:Detecting scenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Transcription saved: extraction_output/sample1_transcription.json\n",
            "   - Language: en\n",
            "   - Segments: 1\n",
            "üé¨ Detecting scene changes in sample1.mp4...\n",
            "‚úÖ Scene detection saved: extraction_output/sample1_scenes.json\n",
            "   - Total scenes: 0\n",
            "üîó Merging data into master log...\n",
            "‚úÖ Master log created: extraction_output/sample1_master_log.json\n",
            "   - Timeline entries: 1\n",
            "\n",
            "============================================================\n",
            "‚úÖ EXTRACTION COMPLETE\n",
            "============================================================\n",
            "Output directory: /content/extraction_output\n",
            "Master log: sample1_master_log.json\n",
            "üìù Modify the video_file path and uncomment to run extraction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIkKRjDNIsYZ",
        "outputId": "1b81bdaf-026a-4d2e-b605-f013a3a3cec6"
      },
      "id": "OIkKRjDNIsYZ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "editing_rules = {\n",
        "    \"editing_rules\": {\n",
        "        \"silence_detection\": {\n",
        "            \"enabled\": True,\n",
        "            \"min_silence_duration\": 1.5,\n",
        "            \"comment\": \"Cut pauses longer than 1.5 seconds\"\n",
        "        },\n",
        "        \"filler_words\": {\n",
        "            \"enabled\": True,\n",
        "            \"words_to_remove\": [\"um\", \"uh\", \"like\", \"you know\", \"basically\", \"actually\"],\n",
        "            \"keep_first_occurrence\": True,\n",
        "            \"comment\": \"Remove filler words but keep first one for natural flow\"\n",
        "        },\n",
        "        \"repetition_detection\": {\n",
        "            \"enabled\": True,\n",
        "            \"similarity_threshold\": 0.8,\n",
        "            \"comment\": \"Remove repeated sentences (keep best take)\"\n",
        "        },\n",
        "        \"pacing_rules\": {\n",
        "            \"max_segment_length\": 30,\n",
        "            \"min_segment_length\": 2,\n",
        "            \"preferred_cut_on_scene_change\": True,\n",
        "            \"comment\": \"Keep segments between 2-30 seconds\"\n",
        "        },\n",
        "        \"content_preservation\": {\n",
        "            \"always_keep_keywords\": [\"important\", \"key point\", \"remember\", \"crucial\"],\n",
        "            \"always_cut_phrases\": [\"let me start over\", \"wait\", \"hold on\"],\n",
        "            \"comment\": \"Force keep/cut based on specific phrases\"\n",
        "        },\n",
        "        \"intro_outro\": {\n",
        "            \"keep_first_seconds\": 5,\n",
        "            \"keep_last_seconds\": 10,\n",
        "            \"comment\": \"Always preserve intro and outro\"\n",
        "        },\n",
        "        \"manual_markers\": {\n",
        "            \"enabled\": True,\n",
        "            \"keep_marker\": \"[KEEP]\",\n",
        "            \"cut_marker\": \"[CUT]\",\n",
        "            \"important_marker\": \"[IMPORTANT]\",\n",
        "            \"comment\": \"Say these words in video to mark segments\"\n",
        "        }\n",
        "    },\n",
        "    \"platform_specific_rules\": {\n",
        "        \"youtube\": {\n",
        "            \"target_length_seconds\": None,\n",
        "            \"hook_duration\": 8\n",
        "        },\n",
        "        \"tiktok\": {\n",
        "            \"target_length_seconds\": 60,\n",
        "            \"max_length_seconds\": 180,\n",
        "            \"hook_duration\": 3\n",
        "        },\n",
        "        \"instagram\": {\n",
        "            \"target_length_seconds\": 90,\n",
        "            \"max_length_seconds\": 90\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to file\n",
        "with open(\"editing_rules.json\", 'w') as f:\n",
        "    json.dump(editing_rules, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ editing_rules.json created!\")\n",
        "print(\"You can now customize these rules for your editing style\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POSWIfs5GhTQ",
        "outputId": "4be7b4a5-2c5f-4aa1-8f9a-e138bb2f77a7"
      },
      "id": "POSWIfs5GhTQ",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ editing_rules.json created!\n",
            "You can now customize these rules for your editing style\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os # Added import os\n",
        "\n",
        "class EditingBrain:\n",
        "    \"\"\"Basic AI analysis using Gemini\"\"\"\n",
        "\n",
        "    def __init__(self, api_key=None):\n",
        "        self.api_key = api_key or os.environ.get(\"GEMINI_API_KEY\")\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"GEMINI_API_KEY required\")\n",
        "\n",
        "        genai.configure(api_key=self.api_key)\n",
        "        self.model = genai.GenerativeModel('gemini-pro-latest') # Changed from gemini-1.5-flash to gemini-pro-latest\n",
        "\n",
        "    def load_master_log(self, master_log_path):\n",
        "        \"\"\"Load master_log.json from Day 1\"\"\"\n",
        "        with open(master_log_path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def analyze_content(self, master_log, editing_style=\"dynamic\"):\n",
        "        \"\"\"Analyze video with AI\"\"\"\n",
        "        print(f\"üß† Analyzing content with '{editing_style}' style...\")\n",
        "\n",
        "        style_instructions = {\n",
        "            \"dynamic\": \"Remove long pauses, cut filler words, keep high-energy segments, tighten pacing\",\n",
        "            \"cinematic\": \"Preserve dramatic pauses, keep emotional moments, maintain artistic timing\",\n",
        "            \"tutorial\": \"Keep all explanations complete, remove only mistakes, preserve structure\",\n",
        "            \"podcast\": \"Keep natural flow, remove only dead air >3s, preserve conversation dynamics\"\n",
        "        }\n",
        "\n",
        "        simplified_timeline = []\n",
        "        for item in master_log['timeline'][:30]:  # Limit for token efficiency\n",
        "            simplified_timeline.append({\n",
        "                'id': item.get('id', item.get('scene_id')),\n",
        "                'type': item['type'],\n",
        "                'start': item['start'],\n",
        "                'end': item['end'],\n",
        "                'duration': item['duration'],\n",
        "                'text': item.get('text', '')\n",
        "            })\n",
        "\n",
        "        prompt = f\"\"\"You are an expert video editor. Analyze this video and decide what to keep/cut.\n",
        "\n",
        "EDITING STYLE: {editing_style}\n",
        "INSTRUCTIONS: {style_instructions[editing_style]}\n",
        "\n",
        "TRANSCRIPT:\n",
        "{master_log['metadata']['full_transcript'][:1000]}\n",
        "\n",
        "TIMELINE:\n",
        "{json.dumps(simplified_timeline, indent=2)}\n",
        "\n",
        "Provide editing decisions in JSON format:\n",
        "{{\n",
        "  \"story_arc\": \"Brief story overview\",\n",
        "  \"pacing_notes\": \"Pacing recommendations\",\n",
        "  \"key_moments\": [{{\"time\": 10.5, \"description\": \"Important moment\"}}],\n",
        "  \"segments\": [\n",
        "    {{\n",
        "      \"id\": 0,\n",
        "      \"action\": \"keep\",\n",
        "      \"reason\": \"Strong hook\",\n",
        "      \"priority\": \"high\"\n",
        "    }}\n",
        "  ]\n",
        "}}\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    temperature=0.3,\n",
        "                    max_output_tokens=4000,\n",
        "                )\n",
        "            )\n",
        "\n",
        "            analysis_text = response.text\n",
        "\n",
        "            # Parse JSON\n",
        "            if \"```json\" in analysis_text:\n",
        "                analysis_text = analysis_text.split(\"```json\")[1].split(\"```\")[0]\n",
        "            elif \"```\" in analysis_text:\n",
        "                analysis_text = analysis_text.split(\"```\")[1].split(\"```\")[0]\n",
        "\n",
        "            analysis = json.loads(analysis_text.strip())\n",
        "\n",
        "            print(f\"‚úÖ Analysis complete\")\n",
        "            print(f\"   - Segments analyzed: {len(analysis.get('segments', []))}\")\n",
        "\n",
        "            return analysis\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def create_edit_decision_list(self, master_log, analysis, editing_style, output_path):\n",
        "        \"\"\"Create EDL combining master_log with AI decisions\"\"\"\n",
        "        print(f\"üìã Creating Edit Decision List...\")\n",
        "\n",
        "        edl = {\n",
        "            \"source_video\": master_log['video_file'],\n",
        "            \"video_path\": master_log.get('video_path', ''),\n",
        "            \"editing_style\": editing_style,\n",
        "            \"story_arc\": analysis.get('story_arc', ''),\n",
        "            \"pacing_notes\": analysis.get('pacing_notes', ''),\n",
        "            \"key_moments\": analysis.get('key_moments', []),\n",
        "            \"cuts\": []\n",
        "        }\n",
        "\n",
        "        segment_decisions = {seg['id']: seg for seg in analysis.get('segments', [])}\n",
        "\n",
        "        for timeline_item in master_log['timeline']:\n",
        "            item_id = timeline_item.get('id', timeline_item.get('scene_id'))\n",
        "            decision = segment_decisions.get(item_id, {'action': 'keep', 'reason': 'No analysis', 'priority': 'medium'})\n",
        "\n",
        "            if decision['action'] == 'keep':\n",
        "                cut = {\n",
        "                    \"segment_id\": item_id,\n",
        "                    \"original_start\": timeline_item['start'],\n",
        "                    \"original_end\": timeline_item['end'],\n",
        "                    \"final_start\": timeline_item['start'],\n",
        "                    \"final_end\": timeline_item['end'],\n",
        "                    \"duration\": timeline_item['duration'],\n",
        "                    \"text\": timeline_item.get('text', ''),\n",
        "                    \"reason\": decision['reason'],\n",
        "                    \"priority\": decision['priority']\n",
        "                }\n",
        "                edl['cuts'].append(cut)\n",
        "\n",
        "        edl['final_duration'] = sum(c['duration'] for c in edl['cuts'])\n",
        "        edl['original_duration'] = master_log['timeline'][-1]['end'] if master_log['timeline'] else 0\n",
        "        edl['time_saved'] = edl['original_duration'] - edl['final_duration']\n",
        "\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(edl, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"‚úÖ EDL created: {output_path}\")\n",
        "        print(f\"   - Original: {edl['original_duration']:.2f}s\")\n",
        "        print(f\"   - Final: {edl['final_duration']:.2f}s\")\n",
        "        print(f\"   - Saved: {edl['time_saved']:.2f}s\")\n",
        "\n",
        "        return edl\n",
        "\n",
        "print(\"‚úÖ Day 2 AI analysis ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArhgWrV0Gl1j",
        "outputId": "6a78e7fe-c671-47f8-bfb8-45a2118712ec"
      },
      "id": "ArhgWrV0Gl1j",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Day 2 AI analysis ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brain = EditingBrain()\n",
        "master_log = brain.load_master_log(\"extraction_output/sample1_master_log.json\")\n",
        "analysis = brain.analyze_content(master_log, editing_style=\"dynamic\")\n",
        "edl = brain.create_edit_decision_list(master_log, analysis, \"dynamic\",\n",
        "                                       \"editing_output/sample_edl.json\")\n",
        "\n",
        "print(\"üìù Uncomment and modify to run AI analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "p7J_A2bSG4kl",
        "outputId": "cab96a30-d213-4988-fc14-eaa0eb6ed584"
      },
      "id": "p7J_A2bSG4kl",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Analyzing content with 'dynamic' style...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 684.60ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Error: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n",
            "Please retry in 7.733540856s.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TooManyRequests",
          "evalue": "429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\nPlease retry in 7.733540856s.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3092224492.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEditingBrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmaster_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_master_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"extraction_output/sample1_master_log.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mediting_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dynamic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m edl = brain.create_edit_decision_list(master_log, analysis, \"dynamic\",\n\u001b[1;32m      5\u001b[0m                                        \"editing_output/sample_edl.json\")\n",
            "\u001b[0;32m/tmp/ipython-input-3661400054.py\u001b[0m in \u001b[0;36manalyze_content\u001b[0;34m(self, master_log, editing_style)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             response = self.model.generate_content(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 generation_config=genai.types.GenerationConfig(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\nPlease retry in 7.733540856s."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "class VideoCutter:\n",
        "    \"\"\"Cut video based on Edit Decision List\"\"\"\n",
        "\n",
        "    def __init__(self, edl_path):\n",
        "        self.edl_path = Path(edl_path)\n",
        "        with open(edl_path, 'r') as f:\n",
        "            self.edl = json.load(f)\n",
        "\n",
        "        self.output_dir = Path(\"final_videos\")\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        self.temp_dir = Path(tempfile.mkdtemp())\n",
        "\n",
        "    def find_video_file(self):\n",
        "        \"\"\"Find source video\"\"\"\n",
        "        if 'video_path' in self.edl:\n",
        "            video_path = Path(self.edl['video_path'])\n",
        "            if video_path.exists():\n",
        "                return video_path\n",
        "\n",
        "        video_path = Path(self.edl['source_video'])\n",
        "        if video_path.exists():\n",
        "            return video_path\n",
        "\n",
        "        raise FileNotFoundError(f\"Video not found: {self.edl['source_video']}\")\n",
        "\n",
        "    def extract_segment(self, video_path, start_time, end_time, output_path):\n",
        "        \"\"\"Extract single segment using FFmpeg\"\"\"\n",
        "        duration = end_time - start_time\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg',\n",
        "            '-ss', str(start_time),\n",
        "            '-i', str(video_path),\n",
        "            '-t', str(duration),\n",
        "            '-c', 'copy',\n",
        "            '-avoid_negative_ts', 'make_zero',\n",
        "            '-y',\n",
        "            str(output_path)\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            subprocess.run(cmd, capture_output=True, check=True)\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def merge_segments(self, segment_files, output_path):\n",
        "        \"\"\"Merge all segments\"\"\"\n",
        "        concat_file = self.temp_dir / \"concat_list.txt\"\n",
        "\n",
        "        with open(concat_file, 'w') as f:\n",
        "            for seg_file in segment_files:\n",
        "                abs_path = seg_file.absolute()\n",
        "                escaped = str(abs_path).replace(\"'\", \"'\\\\''\")\n",
        "                f.write(f\"file '{escaped}'\\n\")\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg',\n",
        "            '-f', 'concat',\n",
        "            '-safe', '0',\n",
        "            '-i', str(concat_file),\n",
        "            '-c', 'copy',\n",
        "            '-y',\n",
        "            str(output_path)\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            subprocess.run(cmd, capture_output=True, check=True)\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def cut_video(self, output_name=None):\n",
        "        \"\"\"Main cutting process\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚úÇÔ∏è  Starting Video Cutting\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        video_path = self.find_video_file()\n",
        "        print(f\"üìπ Source: {video_path}\")\n",
        "        print(f\"‚è±Ô∏è  Original: {self.edl.get('original_duration', 0):.2f}s\")\n",
        "        print(f\"‚è±Ô∏è  Target: {self.edl['final_duration']:.2f}s\\n\")\n",
        "\n",
        "        if not output_name:\n",
        "            video_stem = video_path.stem\n",
        "            style = self.edl.get('editing_style', 'edited')\n",
        "            output_name = f\"{video_stem}_{style}_final.mp4\"\n",
        "\n",
        "        output_path = self.output_dir / output_name\n",
        "\n",
        "        segment_files = []\n",
        "\n",
        "        print(f\"‚úÇÔ∏è  Extracting {len(self.edl['cuts'])} segments...\\n\")\n",
        "\n",
        "        for i, cut in enumerate(self.edl['cuts'], 1):\n",
        "            segment_file = self.temp_dir / f\"segment_{i:04d}.mp4\"\n",
        "\n",
        "            print(f\"  [{i}/{len(self.edl['cuts'])}] {cut['final_start']:.2f}s ‚Üí {cut['final_end']:.2f}s\", end=\" \")\n",
        "\n",
        "            success = self.extract_segment(\n",
        "                video_path,\n",
        "                cut['final_start'],\n",
        "                cut['final_end'],\n",
        "                segment_file\n",
        "            )\n",
        "\n",
        "            if success and segment_file.exists():\n",
        "                segment_files.append(segment_file)\n",
        "                print(\"‚úÖ\")\n",
        "            else:\n",
        "                print(\"‚ùå\")\n",
        "\n",
        "        print(f\"\\n‚úÖ Extracted {len(segment_files)} segments\\n\")\n",
        "\n",
        "        if segment_files:\n",
        "            success = self.merge_segments(segment_files, output_path)\n",
        "\n",
        "            if success:\n",
        "                file_size = output_path.stat().st_size / (1024 * 1024)\n",
        "\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"‚úÖ CUTTING COMPLETE!\")\n",
        "                print(\"=\"*60)\n",
        "                print(f\"üìÅ Output: {output_path}\")\n",
        "                print(f\"üìä Size: {file_size:.2f} MB\")\n",
        "                print(f\"‚è±Ô∏è  Duration: {self.edl['final_duration']:.2f}s\")\n",
        "\n",
        "                return output_path\n",
        "\n",
        "        return None\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Clean up temp files\"\"\"\n",
        "        try:\n",
        "            shutil.rmtree(self.temp_dir)\n",
        "            print(\"üßπ Cleaned up temp files\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print(\"‚úÖ Day 3 cutting engine ready!\")"
      ],
      "metadata": {
        "id": "GUuXDUqCG_hC"
      },
      "id": "GUuXDUqCG_hC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run:\n",
        "cutter = VideoCutter(\"editing_output/sample_edl.json\")\n",
        "output = cutter.cut_video()\n",
        "cutter.cleanup()\n",
        "\n",
        "print(\"üìù Uncomment to run video cutting\")"
      ],
      "metadata": {
        "id": "Qaiua9sVHGOk"
      },
      "id": "Qaiua9sVHGOk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "class CutVisualizer:\n",
        "    \"\"\"Visualize editing decisions before cutting\"\"\"\n",
        "\n",
        "    def __init__(self, edl_path):\n",
        "        self.edl_path = Path(edl_path)\n",
        "        with open(edl_path, 'r') as f:\n",
        "            self.edl = json.load(f)\n",
        "\n",
        "        # Safety fallbacks\n",
        "        if 'cuts' not in self.edl:\n",
        "            self.edl['cuts'] = []\n",
        "\n",
        "        if 'original_duration' not in self.edl or self.edl['original_duration'] == 0:\n",
        "            if self.edl['cuts']:\n",
        "                self.edl['original_duration'] = max(c.get('original_end', 0) for c in self.edl['cuts'])\n",
        "            else:\n",
        "                self.edl['original_duration'] = 1\n",
        "\n",
        "        if 'final_duration' not in self.edl:\n",
        "            self.edl['final_duration'] = sum(c.get('duration', 0) for c in self.edl['cuts'])\n",
        "\n",
        "        if 'time_saved' not in self.edl:\n",
        "            self.edl['time_saved'] = self.edl['original_duration'] - self.edl['final_duration']\n",
        "\n",
        "    def show_timeline(self):\n",
        "        \"\"\"Display visual timeline\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"VISUAL CUT TIMELINE\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "        original_duration = self.edl.get('original_duration', 0)\n",
        "        final_duration = self.edl.get('final_duration', 0)\n",
        "        time_saved = original_duration - final_duration\n",
        "\n",
        "        print(f\"Video: {self.edl.get('source_video', 'video.mp4')}\")\n",
        "        print(f\"Original: {self.format_time(original_duration)}\")\n",
        "        print(f\"Final: {self.format_time(final_duration)}\")\n",
        "        print(f\"Removed: {self.format_time(max(0, time_saved))}\\n\")\n",
        "\n",
        "        if original_duration <= 0:\n",
        "            print(\"‚ùå Error: Cannot generate timeline\")\n",
        "            return\n",
        "\n",
        "        timeline_width = 70\n",
        "        timeline = ['¬∑'] * timeline_width\n",
        "\n",
        "        for cut in self.edl.get('cuts', []):\n",
        "            start_val = cut.get('original_start', cut.get('start', 0))\n",
        "            end_val = cut.get('original_end', cut.get('end', 0))\n",
        "\n",
        "            if start_val is not None and end_val is not None:\n",
        "                start_pos = int((start_val / original_duration) * timeline_width)\n",
        "                end_pos = int((end_val / original_duration) * timeline_width)\n",
        "\n",
        "                for i in range(max(0, start_pos), min(end_pos, timeline_width)):\n",
        "                    timeline[i] = '‚ñà'\n",
        "\n",
        "        print(\"Timeline: (‚ñà = KEEP, ¬∑ = CUT)\")\n",
        "        print(\"‚îú\" + \"‚îÄ\" * timeline_width + \"‚î§\")\n",
        "        print(\"‚îÇ\" + \"\".join(timeline) + \"‚îÇ\")\n",
        "        print(\"‚îú\" + \"‚îÄ\" * timeline_width + \"‚î§\")\n",
        "        print(f\"0s{' ' * (timeline_width - 10)}{self.format_time(original_duration)}\")\n",
        "\n",
        "    def show_cut_list(self):\n",
        "        \"\"\"Show detailed cut list\"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"CUT POINTS LIST\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "        print(f\"{'#':<4} {'TIME RANGE':<25} {'DURATION':<12} {'ACTION':<8} {'REASON'}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i, cut in enumerate(self.edl['cuts'], 1):\n",
        "            orig_start = cut.get('original_start', cut.get('final_start', 0))\n",
        "            orig_end = cut.get('original_end', cut.get('final_end', 0))\n",
        "            duration = cut.get('duration', orig_end - orig_start)\n",
        "\n",
        "            time_range = f\"{self.format_time(orig_start)} ‚Üí {self.format_time(orig_end)}\"\n",
        "            duration_str = self.format_time(duration)\n",
        "\n",
        "            priority_symbol = {'high': '‚≠ê', 'medium': '‚óè', 'low': '‚óã'}.get(cut.get('priority', 'medium'), '‚óè')\n",
        "\n",
        "            reason = cut.get('reason', 'Keep')\n",
        "\n",
        "            print(f\"{i:<4} {time_range:<25} {duration_str:<12} KEEP {priority_symbol}  {reason}\")\n",
        "\n",
        "            if cut.get('text'):\n",
        "                text_preview = cut['text'][:60] + \"...\" if len(cut['text']) > 60 else cut['text']\n",
        "                print(f\"     üí¨ \\\"{text_preview}\\\"\\n\")\n",
        "\n",
        "        print(f\"\\nTotal segments kept: {len(self.edl['cuts'])}\")\n",
        "\n",
        "    def format_time(self, seconds):\n",
        "        \"\"\"Format seconds as MM:SS\"\"\"\n",
        "        td = timedelta(seconds=seconds)\n",
        "        total_seconds = int(td.total_seconds())\n",
        "        hours = total_seconds // 3600\n",
        "        minutes = (total_seconds % 3600) // 60\n",
        "        secs = total_seconds % 60\n",
        "\n",
        "        if hours > 0:\n",
        "            return f\"{hours}:{minutes:02d}:{secs:02d}\"\n",
        "        else:\n",
        "            return f\"{minutes}:{secs:02d}\"\n",
        "\n",
        "print(\"‚úÖ Visual cut marker ready!\")\n"
      ],
      "metadata": {
        "id": "02-zX7AGHNT0"
      },
      "id": "02-zX7AGHNT0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to run:\n",
        "viz = CutVisualizer(\"editing_output/sample_edl.json\")\n",
        "viz.show_timeline()\n",
        "viz.show_cut_list()\n",
        "\n",
        "print(\"üìù Uncomment to preview cuts visually\")"
      ],
      "metadata": {
        "id": "Hf3P5mFsHSqt"
      },
      "id": "Hf3P5mFsHSqt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoEnhancer:\n",
        "    \"\"\"Add professional polish to edited videos\"\"\"\n",
        "\n",
        "    def __init__(self, video_path):\n",
        "        self.video_path = Path(video_path)\n",
        "        if not self.video_path.exists():\n",
        "            raise FileNotFoundError(f\"Video not found: {video_path}\")\n",
        "\n",
        "        self.output_dir = Path(\"enhanced_videos\")\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    def add_background_music(self, music_path, volume=0.3, output_name=None):\n",
        "        \"\"\"Add background music to video\"\"\"\n",
        "        print(\"\\nüéµ Adding background music...\")\n",
        "\n",
        "        music_path = Path(music_path)\n",
        "        if not music_path.exists():\n",
        "            print(f\"‚ùå Music file not found: {music_path}\")\n",
        "            return None\n",
        "\n",
        "        if not output_name:\n",
        "            output_name = f\"{self.video_path.stem}_with_music.mp4\"\n",
        "\n",
        "        output_path = self.output_dir / output_name\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg',\n",
        "            '-i', str(self.video_path),\n",
        "            '-stream_loop', '-1',\n",
        "            '-i', str(music_path),\n",
        "            '-filter_complex',\n",
        "            f'[1:a]volume={volume}[music];[0:a][music]amix=inputs=2:duration=first[aout]',\n",
        "            '-map', '0:v',\n",
        "            '-map', '[aout]',\n",
        "            '-c:v', 'copy',\n",
        "            '-c:a', 'aac',\n",
        "            '-shortest',\n",
        "            '-y',\n",
        "            str(output_path)\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            subprocess.run(cmd, capture_output=True, check=True)\n",
        "            print(f\"‚úÖ Music added: {output_path}\")\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            return None\n",
        "\n",
        "    def export_for_platform(self, platform=\"youtube\", output_name=None):\n",
        "        \"\"\"Export video optimized for specific platforms\"\"\"\n",
        "        print(f\"\\nüì± Exporting for {platform.upper()}...\")\n",
        "\n",
        "        if not output_name:\n",
        "            output_name = f\"{self.video_path.stem}_{platform}.mp4\"\n",
        "\n",
        "        output_path = self.output_dir / output_name\n",
        "\n",
        "        presets = {\n",
        "            \"youtube\": {\n",
        "                \"vf\": \"scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2\",\n",
        "                \"preset\": \"slow\",\n",
        "                \"crf\": \"18\"\n",
        "            },\n",
        "            \"instagram\": {\n",
        "                \"vf\": \"scale=1080:1080:force_original_aspect_ratio=increase,crop=1080:1080\",\n",
        "                \"preset\": \"medium\",\n",
        "                \"crf\": \"23\"\n",
        "            },\n",
        "            \"tiktok\": {\n",
        "                \"vf\": \"scale=1080:1920:force_original_aspect_ratio=increase,crop=1080:1920\",\n",
        "                \"preset\": \"medium\",\n",
        "                \"crf\": \"23\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if platform not in presets:\n",
        "            print(f\"‚ùå Unknown platform: {platform}\")\n",
        "            return None\n",
        "\n",
        "        preset = presets[platform]\n",
        "\n",
        "        cmd = [\n",
        "            'ffmpeg',\n",
        "            '-i', str(self.video_path),\n",
        "            '-vf', preset['vf'],\n",
        "            '-c:v', 'libx264',\n",
        "            '-preset', preset['preset'],\n",
        "            '-crf', preset['crf'],\n",
        "            '-c:a', 'aac',\n",
        "            '-movflags', '+faststart',\n",
        "            '-y',\n",
        "            str(output_path)\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            print(f\"‚è≥ Encoding for {platform}...\")\n",
        "            subprocess.run(cmd, capture_output=True, check=True)\n",
        "            print(f\"‚úÖ Exported: {output_path}\")\n",
        "            return output_path\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "            return None\n",
        "\n",
        "print(\"‚úÖ Day 4 enhancement tools ready!\")"
      ],
      "metadata": {
        "id": "HbGlq55ZHWkD"
      },
      "id": "HbGlq55ZHWkD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_workflow(video_file, editing_style=\"dynamic\"):\n",
        "    \"\"\"\n",
        "    Run complete AI video editing pipeline\n",
        "\n",
        "    Args:\n",
        "        video_file: Path to your video\n",
        "        editing_style: \"dynamic\", \"cinematic\", \"tutorial\", or \"podcast\"\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üé¨ AI VIDEO EDITOR - COMPLETE WORKFLOW\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    video_name = Path(video_file).stem\n",
        "\n",
        "    # DAY 1: Extract data\n",
        "    print(\"üìä DAY 1: Extracting data from video...\")\n",
        "    sensor = VideoSensorSuite(video_file)\n",
        "    master_log = sensor.run_full_extraction(whisper_model=\"base\")\n",
        "\n",
        "    # DAY 2: AI analysis\n",
        "    print(\"\\nüß† DAY 2: AI analyzing content...\")\n",
        "    brain = EditingBrain()\n",
        "    analysis = brain.analyze_content(master_log, editing_style=editing_style)\n",
        "    edl_path = f\"editing_output/{video_name}_edl.json\"\n",
        "    edl = brain.create_edit_decision_list(master_log, analysis, editing_style, edl_path)\n",
        "\n",
        "    # Preview cuts\n",
        "    print(\"\\nüëÅÔ∏è  PREVIEW: Visual timeline...\")\n",
        "    viz = CutVisualizer(edl_path)\n",
        "    viz.show_timeline()\n",
        "    viz.show_cut_list()\n",
        "\n",
        "    # DAY 3: Cut video\n",
        "    print(\"\\n‚úÇÔ∏è  DAY 3: Cutting video...\")\n",
        "    cutter = VideoCutter(edl_path)\n",
        "    final_video = cutter.cut_video()\n",
        "    cutter.cleanup()\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üéâ COMPLETE! Your AI-edited video is ready!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nüìÅ Final video: {final_video}\")\n",
        "    print(f\"üìä Original: {edl['original_duration']:.2f}s\")\n",
        "    print(f\"üìä Final: {edl['final_duration']:.2f}s\")\n",
        "    print(f\"üíæ Saved: {edl['time_saved']:.2f}s ({edl['time_saved']/edl['original_duration']*100:.1f}%)\")\n",
        "    print(f\"\\nüé¨ Ready to share!\")\n",
        "\n",
        "    return final_video\n",
        "\n",
        "# Example usage (uncomment to run):\n",
        "# video = \"your_video.mp4\"\n",
        "# result = complete_workflow(video, editing_style=\"dynamic\")\n",
        "\n",
        "print(\"‚úÖ Complete workflow function ready!\")\n",
        "print(\"\\nUsage: complete_workflow('your_video.mp4', 'dynamic')\")"
      ],
      "metadata": {
        "id": "x_kYJwXXHbv8"
      },
      "id": "x_kYJwXXHbv8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Quick reference for all commands\n",
        "\"\"\"\n",
        "\n",
        "print(\"\"\"\n",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "‚ïë           AI VIDEO EDITOR - QUICK REFERENCE                  ‚ïë\n",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "üìã SETUP (Run once):\n",
        "  1. Install packages (Cell 1)\n",
        "  2. Set GEMINI_API_KEY (Cell 2)\n",
        "  3. Create directories (Cell 3)\n",
        "\n",
        "üé¨ BASIC WORKFLOW (3 steps):\n",
        "\n",
        "  sensor = VideoSensorSuite('video.mp4')\n",
        "  sensor.run_full_extraction()\n",
        "\n",
        "  brain = EditingBrain()\n",
        "  master_log = brain.load_master_log('extraction_output/video_master_log.json')\n",
        "  analysis = brain.analyze_content(master_log, 'dynamic')\n",
        "  edl = brain.create_edit_decision_list(master_log, analysis, 'dynamic', 'editing_output/video_edl.json')\n",
        "\n",
        "  cutter = VideoCutter('editing_output/video_edl.json')\n",
        "  cutter.cut_video()\n",
        "\n",
        "üé® EDITING STYLES:\n",
        "  - \"dynamic\"    : Fast-paced, YouTube, social media\n",
        "  - \"cinematic\"  : Artistic, dramatic, films\n",
        "  - \"tutorial\"   : Educational, clear, structured\n",
        "  - \"podcast\"    : Natural conversation flow\n",
        "\n",
        "üëÅÔ∏è  PREVIEW CUTS FIRST:\n",
        "  viz = CutVisualizer('editing_output/video_edl.json')\n",
        "  viz.show_timeline()\n",
        "  viz.show_cut_list()\n",
        "\n",
        "‚ú® ADD ENHANCEMENTS:\n",
        "  enhancer = VideoEnhancer('final_videos/video_final.mp4')\n",
        "  enhancer.add_background_music('music.mp3')\n",
        "  enhancer.export_for_platform('youtube')\n",
        "\n",
        "üöÄ COMPLETE AUTO-WORKFLOW:\n",
        "  complete_workflow('your_video.mp4', 'dynamic')\n",
        "\n",
        "üìÅ OUTPUT LOCATIONS:\n",
        "  extraction_output/  ‚Üí Day 1 outputs\n",
        "  editing_output/     ‚Üí Day 2 outputs (EDL files)\n",
        "  final_videos/       ‚Üí Day 3 outputs (edited videos)\n",
        "  enhanced_videos/    ‚Üí Day 4 outputs (polished videos)\n",
        "\n",
        "üí° TIPS:\n",
        "  - Start with 1-2 minute test video\n",
        "  - Try different editing styles\n",
        "  - Preview before cutting\n",
        "  - Customize editing_rules.json for control\n",
        "\n",
        "üÜò HELP:\n",
        "  - Check GEMINI_API_KEY is set\n",
        "  - Ensure FFmpeg is installed\n",
        "  - Video file path is correct\n",
        "  - Check error messages in output\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ufR1vSDIHgyE"
      },
      "id": "ufR1vSDIHgyE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Common issues and solutions\n",
        "\"\"\"\n",
        "\n",
        "def check_setup():\n",
        "    \"\"\"Check if everything is set up correctly\"\"\"\n",
        "\n",
        "    print(\"\\nüîç Checking setup...\\n\")\n",
        "\n",
        "    issues = []\n",
        "\n",
        "    # Check API key\n",
        "    api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    if api_key:\n",
        "        print(f\"‚úÖ GEMINI_API_KEY is set ({api_key[:10]}...)\")\n",
        "    else:\n",
        "        print(\"‚ùå GEMINI_API_KEY is not set\")\n",
        "        issues.append(\"Set API key in Cell 2\")\n",
        "\n",
        "    # Check FFmpeg\n",
        "    try:\n",
        "        result = subprocess.run(['ffmpeg', '-version'], capture_output=True)\n",
        "        print(\"‚úÖ FFmpeg is installed\")\n",
        "    except:\n",
        "        print(\"‚ùå FFmpeg is not installed\")\n",
        "        issues.append(\"Install FFmpeg: brew install ffmpeg (Mac)\")\n",
        "\n",
        "    # Check directories\n",
        "    dirs = ['extraction_output', 'editing_output', 'final_videos']\n",
        "    all_exist = all(Path(d).exists() for d in dirs)\n",
        "    if all_exist:\n",
        "        print(\"‚úÖ Project directories exist\")\n",
        "    else:\n",
        "        print(\"‚ùå Some directories missing\")\n",
        "        issues.append(\"Run Cell 3 to create directories\")\n",
        "\n",
        "    # Check imports\n",
        "    try:\n",
        "        import whisper\n",
        "        import scenedetect\n",
        "        import google.generativeai\n",
        "        print(\"‚úÖ All Python packages installed\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå Missing package: {e}\")\n",
        "        issues.append(\"Run Cell 1 to install packages\")\n",
        "\n",
        "    if issues:\n",
        "        print(\"\\n‚ö†Ô∏è  Issues found:\")\n",
        "        for i, issue in enumerate(issues, 1):\n",
        "            print(f\"  {i}. {issue}\")\n",
        "    else:\n",
        "        print(\"\\nüéâ Everything looks good! Ready to edit videos!\")\n",
        "\n",
        "    return len(issues) == 0\n",
        "\n",
        "# Run check\n",
        "check_setup()"
      ],
      "metadata": {
        "id": "2WeNPSYRHpdz"
      },
      "id": "2WeNPSYRHpdz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}